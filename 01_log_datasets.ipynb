{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "237df40f-fa27-4183-a9dc-07d946ef2055",
   "metadata": {},
   "source": [
    "# Download and Log data to W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443aa4c8-9fce-4e26-a16d-e864743ef667",
   "metadata": {
    "id": "81fa2c02"
   },
   "source": [
    "For our tutorial, we will use a small part of the Hi-Fi Multi-Speaker English TTS (Hi-Fi TTS) dataset. You can read more about dataset [here](https://arxiv.org/abs/2104.01497). We will use speaker 9017 as the target speaker, and only a 5-minute subset of audio will be used for this fine-tuning example. We additionally resample audio to 22050 kHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e33bf9-03a8-4f60-8abe-71a6cfcdc587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b94be3-4de9-484a-906f-c7dda4232b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEAKER_ID = \"lukas\"\n",
    "WANDB_PROJECT = \"tts-lukas\"\n",
    "WANDB_ENTITY = \"capecape\" # replace with your wandb username or team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "637890c4-a89c-4c5e-9261-260fd96b805e",
   "metadata": {
    "id": "VIFgqxLOpxha"
   },
   "outputs": [],
   "source": [
    "# !unzip -q lukas.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44653589-48d4-4819-973b-d38b9f65dd1e",
   "metadata": {
    "id": "gSQqq0fBqy8K"
   },
   "source": [
    "Looking at `manifest.json`, we see a standard NeMo json that contains the filepath, text, and duration. Please note that our `manifest.json` contains the relative path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a939ba6-9327-4e1e-ab33-49a3607a9b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(f\"{SPEAKER_ID}/manifest.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a3de213-4df3-43ec-a6fc-5ecf0d31239c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_filepath</th>\n",
       "      <th>text</th>\n",
       "      <th>duration</th>\n",
       "      <th>text_no_preprocessing</th>\n",
       "      <th>text_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lukas/seg0.wav</td>\n",
       "      <td>Today we're going to talk about the big picture.</td>\n",
       "      <td>3.28</td>\n",
       "      <td>Today we're going to talk about the big picture.</td>\n",
       "      <td>Today we're going to talk about the big picture.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lukas/seg1.wav</td>\n",
       "      <td>What is machine learning? What is deep learning?</td>\n",
       "      <td>2.64</td>\n",
       "      <td>What is machine learning? What is deep learning?</td>\n",
       "      <td>What is machine learning? What is deep learning?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lukas/seg2.wav</td>\n",
       "      <td>How does it really work and where can we appl...</td>\n",
       "      <td>2.88</td>\n",
       "      <td>How does it really work and where can we appl...</td>\n",
       "      <td>How does it really work and where can we apply...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lukas/seg3.wav</td>\n",
       "      <td>And unlike some of the other videos that we'r...</td>\n",
       "      <td>2.80</td>\n",
       "      <td>And unlike some of the other videos that we'r...</td>\n",
       "      <td>And unlike some of the other videos that we're...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lukas/seg4.wav</td>\n",
       "      <td>this isn't just for engineers.</td>\n",
       "      <td>1.52</td>\n",
       "      <td>this isn't just for engineers.</td>\n",
       "      <td>this isn't just for engineers.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   audio_filepath                                               text  \\\n",
       "0  lukas/seg0.wav   Today we're going to talk about the big picture.   \n",
       "1  lukas/seg1.wav   What is machine learning? What is deep learning?   \n",
       "2  lukas/seg2.wav   How does it really work and where can we appl...   \n",
       "3  lukas/seg3.wav   And unlike some of the other videos that we'r...   \n",
       "4  lukas/seg4.wav                     this isn't just for engineers.   \n",
       "\n",
       "   duration                              text_no_preprocessing  \\\n",
       "0      3.28   Today we're going to talk about the big picture.   \n",
       "1      2.64   What is machine learning? What is deep learning?   \n",
       "2      2.88   How does it really work and where can we appl...   \n",
       "3      2.80   And unlike some of the other videos that we'r...   \n",
       "4      1.52                     this isn't just for engineers.   \n",
       "\n",
       "                                     text_normalized  \n",
       "0   Today we're going to talk about the big picture.  \n",
       "1   What is machine learning? What is deep learning?  \n",
       "2  How does it really work and where can we apply...  \n",
       "3  And unlike some of the other videos that we're...  \n",
       "4                     this isn't just for engineers.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf73a9-7d93-4fd4-b294-01084fc26356",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af09cce0-9f41-44c2-b3f1-47964c7dd530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/NVIDIA/NeMo/main/scripts/dataset_processing/tts/compute_speaker_stats.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b97d004-9177-4a56-be52-a9f68aa88e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-08 13:49:53 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-08 13:49:56 tokenize_and_classify:87] Creating ClassifyFst grammars.\n"
     ]
    }
   ],
   "source": [
    "from nemo_text_processing.text_normalization.normalize import Normalizer\n",
    "normalizer = Normalizer(input_case='cased', lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd2f2e18-8ed7-47c1-9729-7126aca2cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text_normalized = df.text.apply(normalizer.normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3238c6bd-5038-499e-88d1-9ce1fdf47b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_records = df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "935a5939-728b-405b-b321-10617f975ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ndjson\n",
    "with open(\"lukas/manifest.json\", 'w') as f:\n",
    "    ndjson.dump(dict_records, f,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dae4615-dc17-4504-bc7c-e658f94ce293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this line does not work!\n",
    "# df.to_json(\"manifest_n.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3279836b-c018-41d2-ad92-2768e5778dae",
   "metadata": {},
   "source": [
    "## Save to W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a68694c-957c-4de1-b8f1-6a6c1a6517e8",
   "metadata": {},
   "source": [
    "Let's log this raw data to W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc668da7-b00d-4f02-9822-ebff2f594658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcapecape\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tcapelle/wandb/nvidia-workshop/wandb/run-20221208_135035-luz3qff8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/capecape/tts-lukas/runs/luz3qff8\" target=\"_blank\">desert-energy-1</a></strong> to <a href=\"https://wandb.ai/capecape/tts-lukas\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/capecape/tts-lukas/runs/luz3qff8?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f28d5b15b20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=WANDB_PROJECT, entity=WANDB_ENTITY, job_type=\"log_dataset\", config={\"speaker_id\":SPEAKER_ID})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78133312-9913-438a-bdda-e3915a6ab09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "at = wandb.Artifact(\"lukas_data\", type=\"dataset\", description=f\"Speaker {SPEAKER_ID} from ML course from YouTube\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07e24b61-6b7a-438e-9587-9236b9461379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./lukas)... Done. 0.2s\n"
     ]
    }
   ],
   "source": [
    "at.add_dir(f\"lukas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "144dc20d-831b-4eaf-8190-ff6462b9d08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7f28d5b7a640>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.log_artifact(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ced4231-e615-4155-8826-08a92adcba0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">desert-energy-1</strong>: <a href=\"https://wandb.ai/capecape/tts-lukas/runs/luz3qff8\" target=\"_blank\">https://wandb.ai/capecape/tts-lukas/runs/luz3qff8</a><br/>Synced 6 W&B file(s), 0 media file(s), 244 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221208_135035-luz3qff8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec04f1-e9d2-4cc4-918f-e282b2dfc5ff",
   "metadata": {},
   "source": [
    "### Train/Val split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f9069-4d95-4929-878d-a7ebf1d2b916",
   "metadata": {},
   "source": [
    "Let's take 2 samples from the dataset and split it off into a validation set. Then, split all other samples into the training set.\n",
    "\n",
    "As mentioned, since the paths in the manifest are relative, we also create a symbolic link to the audio folder such that `audio/` goes to the correct directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cfce83e-39c5-4088-a0fc-1dc401c2b703",
   "metadata": {
    "id": "B8gVfp5SsuDd"
   },
   "outputs": [],
   "source": [
    "!cat ./{SPEAKER_ID}/manifest.json | tail -n 5 > ./{SPEAKER_ID}_manifest_valid_local.json\n",
    "!cat ./{SPEAKER_ID}/manifest.json | head -n -5 > ./{SPEAKER_ID}_manifest_train_local.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e93d72f-d1fb-4db9-b3c8-e066c226c9ea",
   "metadata": {},
   "source": [
    "Let's log the split files to W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8b3f582-dff9-414a-9406-af0743f49e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tcapelle/wandb/nvidia-workshop/wandb/run-20221208_135049-1w453tbr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/capecape/tts-lukas/runs/1w453tbr\" target=\"_blank\">drawn-yogurt-2</a></strong> to <a href=\"https://wandb.ai/capecape/tts-lukas\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=WANDB_PROJECT, entity=WANDB_ENTITY,  job_type=\"dataset_split\", config={\"speaker_id\":SPEAKER_ID})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e109301-c432-4799-a597-703087d1df65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Artifact QXJ0aWZhY3Q6Mjk1MjY4NzQz>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.use_artifact(f'{WANDB_ENTITY}/{WANDB_PROJECT}/lukas_data:latest', type='dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c85f90f5-0d09-4ec3-812d-39db7c480f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "at = wandb.Artifact(\"lukas_split\", type=\"dataset_split\", description=f\"Train/valid split for Speaker {SPEAKER_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e89f111d-e3e7-4b84-9707-830d602e158b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ManifestEntry digest: z5Wzrg8vIQ1IoGpUvnWHJw==>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at.add_file(f\"./{SPEAKER_ID}_manifest_train_local.json\")\n",
    "at.add_file(f\"./{SPEAKER_ID}_manifest_valid_local.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "737efca1-78f3-4704-988f-d3a8cbe63ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7f28d5ab7fd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.log_artifact(at)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f0a6c9-3e07-4204-855f-ba05281e5cd8",
   "metadata": {},
   "source": [
    "## ðŸ‘€ Visualizing the dataset (or playing the audio ðŸ¤£)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8c0ef-f538-4cd5-ad13-dd0a27bf74d7",
   "metadata": {},
   "source": [
    "Let's create a W&B Table to inspect these files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d91fd363-203a-4439-8085-777fd467d2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_filepath</th>\n",
       "      <th>text</th>\n",
       "      <th>duration</th>\n",
       "      <th>text_no_preprocessing</th>\n",
       "      <th>text_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lukas/seg0.wav</td>\n",
       "      <td>Today we're going to talk about the big picture.</td>\n",
       "      <td>3.28</td>\n",
       "      <td>Today we're going to talk about the big picture.</td>\n",
       "      <td>Today we're going to talk about the big picture.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lukas/seg1.wav</td>\n",
       "      <td>What is machine learning? What is deep learning?</td>\n",
       "      <td>2.64</td>\n",
       "      <td>What is machine learning? What is deep learning?</td>\n",
       "      <td>What is machine learning? What is deep learning?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lukas/seg2.wav</td>\n",
       "      <td>How does it really work and where can we appl...</td>\n",
       "      <td>2.88</td>\n",
       "      <td>How does it really work and where can we appl...</td>\n",
       "      <td>How does it really work and where can we apply...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lukas/seg3.wav</td>\n",
       "      <td>And unlike some of the other videos that we'r...</td>\n",
       "      <td>2.80</td>\n",
       "      <td>And unlike some of the other videos that we'r...</td>\n",
       "      <td>And unlike some of the other videos that we're...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lukas/seg4.wav</td>\n",
       "      <td>this isn't just for engineers.</td>\n",
       "      <td>1.52</td>\n",
       "      <td>this isn't just for engineers.</td>\n",
       "      <td>this isn't just for engineers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>lukas/seg233.wav</td>\n",
       "      <td>specific API that's common to all machine lea...</td>\n",
       "      <td>6.00</td>\n",
       "      <td>specific API that's common to all machine lea...</td>\n",
       "      <td>specific API that's common to all machine lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>lukas/seg234.wav</td>\n",
       "      <td>thinking, okay, is my problem suitable for ma...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>thinking, okay, is my problem suitable for ma...</td>\n",
       "      <td>thinking, okay, is my problem suitable for mac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>lukas/seg235.wav</td>\n",
       "      <td>asking yourself is, can I turn it into this k...</td>\n",
       "      <td>6.00</td>\n",
       "      <td>asking yourself is, can I turn it into this k...</td>\n",
       "      <td>asking yourself is, can I turn it into this ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>lukas/seg236.wav</td>\n",
       "      <td>numbers as input and a fixed length of number...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>numbers as input and a fixed length of number...</td>\n",
       "      <td>numbers as input and a fixed length of numbers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>lukas/seg237.wav</td>\n",
       "      <td>examples to show my model to build my machine...</td>\n",
       "      <td>6.00</td>\n",
       "      <td>examples to show my model to build my machine...</td>\n",
       "      <td>examples to show my model to build my machine ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       audio_filepath                                               text  \\\n",
       "0      lukas/seg0.wav   Today we're going to talk about the big picture.   \n",
       "1      lukas/seg1.wav   What is machine learning? What is deep learning?   \n",
       "2      lukas/seg2.wav   How does it really work and where can we appl...   \n",
       "3      lukas/seg3.wav   And unlike some of the other videos that we'r...   \n",
       "4      lukas/seg4.wav                     this isn't just for engineers.   \n",
       "..                ...                                                ...   \n",
       "233  lukas/seg233.wav   specific API that's common to all machine lea...   \n",
       "234  lukas/seg234.wav   thinking, okay, is my problem suitable for ma...   \n",
       "235  lukas/seg235.wav   asking yourself is, can I turn it into this k...   \n",
       "236  lukas/seg236.wav   numbers as input and a fixed length of number...   \n",
       "237  lukas/seg237.wav   examples to show my model to build my machine...   \n",
       "\n",
       "     duration                              text_no_preprocessing  \\\n",
       "0        3.28   Today we're going to talk about the big picture.   \n",
       "1        2.64   What is machine learning? What is deep learning?   \n",
       "2        2.88   How does it really work and where can we appl...   \n",
       "3        2.80   And unlike some of the other videos that we'r...   \n",
       "4        1.52                     this isn't just for engineers.   \n",
       "..        ...                                                ...   \n",
       "233      6.00   specific API that's common to all machine lea...   \n",
       "234      5.00   thinking, okay, is my problem suitable for ma...   \n",
       "235      6.00   asking yourself is, can I turn it into this k...   \n",
       "236      5.00   numbers as input and a fixed length of number...   \n",
       "237      6.00   examples to show my model to build my machine...   \n",
       "\n",
       "                                       text_normalized  \n",
       "0     Today we're going to talk about the big picture.  \n",
       "1     What is machine learning? What is deep learning?  \n",
       "2    How does it really work and where can we apply...  \n",
       "3    And unlike some of the other videos that we're...  \n",
       "4                       this isn't just for engineers.  \n",
       "..                                                 ...  \n",
       "233  specific API that's common to all machine lear...  \n",
       "234  thinking, okay, is my problem suitable for mac...  \n",
       "235  asking yourself is, can I turn it into this ki...  \n",
       "236  numbers as input and a fixed length of numbers...  \n",
       "237  examples to show my model to build my machine ...  \n",
       "\n",
       "[238 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_json(f\"{SPEAKER_ID}_manifest_train_local.json\", lines=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bfc836-d29e-4a4b-923c-a8f49c7648a8",
   "metadata": {},
   "source": [
    "create a `wandb.Table` from a `DataFrame`\n",
    "- We need to convert the audio files paths to `wandb.Audio` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10fe14ab-36d4-4e93-91c8-660ab9838699",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.audio_filepath = train_df.audio_filepath.apply(wandb.Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff094ecc-7718-4390-b4bc-7875ab241eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table = wandb.Table(dataframe=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06769e06-b3df-477a-86a4-12efa125f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"train_data\": train_table})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efa32c6-66da-4f47-b60a-63d4472fa7a7",
   "metadata": {},
   "source": [
    "We can do the same with the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1475740-8817-4bad-ba31-1ce86d68655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_json(f\"{SPEAKER_ID}_manifest_valid_local.json\", lines=True)\n",
    "valid_df.audio_filepath = valid_df.audio_filepath.apply(wandb.Audio)\n",
    "valid_table = wandb.Table(dataframe=valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b32ff7c-4ff8-46c0-a9e1-adc8e19acd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"valid_data\": valid_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "055f6d6b-2aab-4501-824c-04295929c4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectTimeout), entering retry loop.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">drawn-yogurt-2</strong>: <a href=\"https://wandb.ai/capecape/tts-lukas/runs/1w453tbr\" target=\"_blank\">https://wandb.ai/capecape/tts-lukas/runs/1w453tbr</a><br/>Synced 5 W&B file(s), 2 media file(s), 247 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221208_135049-1w453tbr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

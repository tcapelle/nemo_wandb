{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d1b76f3-d4b0-4d9f-b8f4-2c23e3d635ae",
   "metadata": {},
   "source": [
    "# Download and Log data to W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443aa4c8-9fce-4e26-a16d-e864743ef667",
   "metadata": {
    "id": "81fa2c02"
   },
   "source": [
    "For our tutorial, we will use a small part of the Hi-Fi Multi-Speaker English TTS (Hi-Fi TTS) dataset. You can read more about dataset [here](https://arxiv.org/abs/2104.01497). We will use speaker 9017 as the target speaker, and only a 5-minute subset of audio will be used for this fine-tuning example. We additionally resample audio to 22050 kHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c7b94be3-4de9-484a-906f-c7dda4232b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "config = SimpleNamespace(SPEAKER_ID = \"9017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "637890c4-a89c-4c5e-9261-260fd96b805e",
   "metadata": {
    "id": "VIFgqxLOpxha"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-06 15:14:12--  https://multilangaudiosamples.s3.us-east-2.amazonaws.com/9017_5_mins.tar.gz\n",
      "Resolving multilangaudiosamples.s3.us-east-2.amazonaws.com (multilangaudiosamples.s3.us-east-2.amazonaws.com)... 52.219.178.42\n",
      "Connecting to multilangaudiosamples.s3.us-east-2.amazonaws.com (multilangaudiosamples.s3.us-east-2.amazonaws.com)|52.219.178.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10802737 (10M) [application/x-gzip]\n",
      "Saving to: ‘9017_5_mins.tar.gz.1’\n",
      "\n",
      "9017_5_mins.tar.gz. 100%[===================>]  10.30M  38.0MB/s    in 0.3s    \n",
      "\n",
      "2022-12-06 15:14:12 (38.0 MB/s) - ‘9017_5_mins.tar.gz.1’ saved [10802737/10802737]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://multilangaudiosamples.s3.us-east-2.amazonaws.com/\"{config.SPEAKER_ID}_5_mins.tar.gz\"  # Contains 10MB of data\n",
    "!tar -xzf \"{config.SPEAKER_ID}_5_mins.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44653589-48d4-4819-973b-d38b9f65dd1e",
   "metadata": {
    "id": "gSQqq0fBqy8K"
   },
   "source": [
    "Looking at `manifest.json`, we see a standard NeMo json that contains the filepath, text, and duration. Please note that our `manifest.json` contains the relative path.\n",
    "\n",
    "Let's make sure that the entries look something like this:\n",
    "\n",
    "```\n",
    "{\"audio_filepath\": \"audio/presentpictureofnsw_02_mann_0532.wav\", \"text\": \"not to stop more than ten minutes by the way\", \"duration\": 2.6, \"text_no_preprocessing\": \"not to stop more than ten minutes by the way,\", \"text_normalized\": \"not to stop more than ten minutes by the way,\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d76f48af-831e-4802-b32d-07a18fab6598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"audio_filepath\": \"audio/dartagnan03part1_027_dumas_0047.wav\", \"text\": \"yes monsieur\", \"duration\": 1.04, \"text_no_preprocessing\": \"Yes, monsieur.\", \"text_normalized\": \"Yes, monsieur.\"}\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 ./{config.SPEAKER_ID}_5_mins/manifest.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f9069-4d95-4929-878d-a7ebf1d2b916",
   "metadata": {},
   "source": [
    "Let's take 2 samples from the dataset and split it off into a validation set. Then, split all other samples into the training set.\n",
    "\n",
    "As mentioned, since the paths in the manifest are relative, we also create a symbolic link to the audio folder such that `audio/` goes to the correct directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5cfce83e-39c5-4088-a0fc-1dc401c2b703",
   "metadata": {
    "id": "B8gVfp5SsuDd"
   },
   "outputs": [],
   "source": [
    "!cat ./{config.SPEAKER_ID}_5_mins/manifest.json | tail -n 2 > ./{config.SPEAKER_ID}_manifest_valid_local.json\n",
    "!cat ./{config.SPEAKER_ID}_5_mins/manifest.json | head -n -2 > ./{config.SPEAKER_ID}_manifest_train_local.json\n",
    "!ln -s ./{config.SPEAKER_ID}_5_mins/audio audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8c0ef-f538-4cd5-ad13-dd0a27bf74d7",
   "metadata": {},
   "source": [
    "Let's create a W&B Table to inspect these files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "68e33bf9-03a8-4f60-8abe-71a6cfcdc587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d91fd363-203a-4439-8085-777fd467d2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_filepath</th>\n",
       "      <th>text</th>\n",
       "      <th>duration</th>\n",
       "      <th>text_no_preprocessing</th>\n",
       "      <th>text_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio/dartagnan03part1_027_dumas_0047.wav</td>\n",
       "      <td>yes monsieur</td>\n",
       "      <td>1.04</td>\n",
       "      <td>Yes, monsieur.</td>\n",
       "      <td>Yes, monsieur.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio/dartagnan01_42_dumas_0220.wav</td>\n",
       "      <td>asked he in an undertone</td>\n",
       "      <td>1.66</td>\n",
       "      <td>asked he, in an undertone.</td>\n",
       "      <td>asked he, in an undertone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio/dartagnan01_38_dumas_0123.wav</td>\n",
       "      <td>grimaud entered</td>\n",
       "      <td>1.20</td>\n",
       "      <td>Grimaud entered.</td>\n",
       "      <td>Grimaud entered.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio/dartagnan01_53_dumas_0059.wav</td>\n",
       "      <td>in the morning when they entered milady's cham...</td>\n",
       "      <td>3.70</td>\n",
       "      <td>In the morning, when they entered Milady's cha...</td>\n",
       "      <td>In the morning, when they entered Milady's cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio/dartagnan03part3_66_dumas_0203.wav</td>\n",
       "      <td>yes monseigneur</td>\n",
       "      <td>1.42</td>\n",
       "      <td>“Yes, monseigneur.</td>\n",
       "      <td>Yes, monseigneur.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>audio/dartagnan03part3_09_dumas_0218.wav</td>\n",
       "      <td>and so you are determined to sign the sale of ...</td>\n",
       "      <td>8.76</td>\n",
       "      <td>“And so you are determined to sign the sale of...</td>\n",
       "      <td>And so you are determined to sign the sale of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>audio/dartagnan01_62_dumas_0190.wav</td>\n",
       "      <td>what</td>\n",
       "      <td>0.58</td>\n",
       "      <td>“What?”</td>\n",
       "      <td>\"What?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>audio/dartagnan01_33_dumas_0018.wav</td>\n",
       "      <td>well what is to be done</td>\n",
       "      <td>1.90</td>\n",
       "      <td>“Well, what is to be done?”</td>\n",
       "      <td>\"Well, what is to be done?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>audio/dartagnan03part3_62_dumas_0243.wav</td>\n",
       "      <td>said grimaud addressing athos and pointing to ...</td>\n",
       "      <td>7.88</td>\n",
       "      <td>said Grimaud, addressing Athos and pointing to...</td>\n",
       "      <td>said Grimaud, addressing Athos and pointing to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>audio/dartagnan03part1_094_dumas_0124.wav</td>\n",
       "      <td>i am captain of the musketeers</td>\n",
       "      <td>2.00</td>\n",
       "      <td>I am captain of the musketeers;</td>\n",
       "      <td>I am captain of the musketeers;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               audio_filepath  \\\n",
       "0   audio/dartagnan03part1_027_dumas_0047.wav   \n",
       "1         audio/dartagnan01_42_dumas_0220.wav   \n",
       "2         audio/dartagnan01_38_dumas_0123.wav   \n",
       "3         audio/dartagnan01_53_dumas_0059.wav   \n",
       "4    audio/dartagnan03part3_66_dumas_0203.wav   \n",
       "..                                        ...   \n",
       "71   audio/dartagnan03part3_09_dumas_0218.wav   \n",
       "72        audio/dartagnan01_62_dumas_0190.wav   \n",
       "73        audio/dartagnan01_33_dumas_0018.wav   \n",
       "74   audio/dartagnan03part3_62_dumas_0243.wav   \n",
       "75  audio/dartagnan03part1_094_dumas_0124.wav   \n",
       "\n",
       "                                                 text  duration  \\\n",
       "0                                        yes monsieur      1.04   \n",
       "1                            asked he in an undertone      1.66   \n",
       "2                                     grimaud entered      1.20   \n",
       "3   in the morning when they entered milady's cham...      3.70   \n",
       "4                                     yes monseigneur      1.42   \n",
       "..                                                ...       ...   \n",
       "71  and so you are determined to sign the sale of ...      8.76   \n",
       "72                                               what      0.58   \n",
       "73                            well what is to be done      1.90   \n",
       "74  said grimaud addressing athos and pointing to ...      7.88   \n",
       "75                     i am captain of the musketeers      2.00   \n",
       "\n",
       "                                text_no_preprocessing  \\\n",
       "0                                      Yes, monsieur.   \n",
       "1                          asked he, in an undertone.   \n",
       "2                                    Grimaud entered.   \n",
       "3   In the morning, when they entered Milady's cha...   \n",
       "4                                  “Yes, monseigneur.   \n",
       "..                                                ...   \n",
       "71  “And so you are determined to sign the sale of...   \n",
       "72                                            “What?”   \n",
       "73                        “Well, what is to be done?”   \n",
       "74  said Grimaud, addressing Athos and pointing to...   \n",
       "75                    I am captain of the musketeers;   \n",
       "\n",
       "                                      text_normalized  \n",
       "0                                      Yes, monsieur.  \n",
       "1                          asked he, in an undertone.  \n",
       "2                                    Grimaud entered.  \n",
       "3   In the morning, when they entered Milady's cha...  \n",
       "4                                   Yes, monseigneur.  \n",
       "..                                                ...  \n",
       "71  And so you are determined to sign the sale of ...  \n",
       "72                                            \"What?\"  \n",
       "73                        \"Well, what is to be done?\"  \n",
       "74  said Grimaud, addressing Athos and pointing to...  \n",
       "75                    I am captain of the musketeers;  \n",
       "\n",
       "[76 rows x 5 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_json(f\"{config.SPEAKER_ID}_manifest_train_local.json\", lines=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bfc836-d29e-4a4b-923c-a8f49c7648a8",
   "metadata": {},
   "source": [
    "create a `wandb.Table` from a `DataFrame`\n",
    "- We need to convert the audio files paths to `wandb.Audio` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "10fe14ab-36d4-4e93-91c8-660ab9838699",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.audio_filepath = train_df.audio_filepath.apply(wandb.Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ff094ecc-7718-4390-b4bc-7875ab241eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table = wandb.Table(dataframe=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "89092a7e-4d23-4631-a73e-b514c51e2267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tcapelle/wandb/nvidia-workshop/wandb/run-20221206_151415-1we18lgr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/capecape/nemo/runs/1we18lgr\" target=\"_blank\">glorious-glade-8</a></strong> to <a href=\"https://wandb.ai/capecape/nemo\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/capecape/nemo/runs/1we18lgr?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f90077655b0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"nemo\", job_type=\"log_dataset\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "06769e06-b3df-477a-86a4-12efa125f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"train_data\": train_table})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efa32c6-66da-4f47-b60a-63d4472fa7a7",
   "metadata": {},
   "source": [
    "We can do the same with the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b1475740-8817-4bad-ba31-1ce86d68655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_json(f\"{config.SPEAKER_ID}_manifest_valid_local.json\", lines=True)\n",
    "valid_df.audio_filepath = valid_df.audio_filepath.apply(wandb.Audio)\n",
    "valid_table = wandb.Table(dataframe=valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "055f6d6b-2aab-4501-824c-04295929c4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fba546b1c8432d9f9e864cf79fec0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='12.257 MB of 12.272 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9988…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">glorious-glade-8</strong>: <a href=\"https://wandb.ai/capecape/nemo/runs/1we18lgr\" target=\"_blank\">https://wandb.ai/capecape/nemo/runs/1we18lgr</a><br/>Synced 5 W&B file(s), 1 media file(s), 77 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221206_151415-1we18lgr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c5383e-567e-4b67-902e-22c6767b52ac",
   "metadata": {
    "id": "lhhg2wBNtW0r"
   },
   "source": [
    "Let's also download the pretrained checkpoint that we want to finetune from. NeMo will save checkpoints to `~/.cache`, so let's move that to our current directory. \n",
    "\n",
    "*Note: please, check that `home_path` refers to your home folder. Otherwise, change it manually.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f9795-e97c-45d1-8f7a-a9deecbf209e",
   "metadata": {},
   "source": [
    "## Download Necessary files for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e18141-cb1f-4211-9388-bed152c34393",
   "metadata": {
    "id": "6c8b13b8"
   },
   "source": [
    "To finetune the FastPitch model on the above created filelists, we use the `examples/tts/fastpitch_finetune.py` script to train the models with the `fastpitch_align_v1.05.yaml` configuration.\n",
    "\n",
    "Let's grab those files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e1e484a3-d300-4121-8233-cddc8c02be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRANCH = \"master\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "200c7b26",
   "metadata": {
    "id": "3zg2H-32dNBU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-06 15:22:23--  https://raw.githubusercontent.com/nvidia/NeMo/master/examples/tts/fastpitch_finetune.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1751 (1.7K) [text/plain]\n",
      "Saving to: ‘fastpitch_finetune.py.1’\n",
      "\n",
      "fastpitch_finetune. 100%[===================>]   1.71K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-12-06 15:22:23 (39.5 MB/s) - ‘fastpitch_finetune.py.1’ saved [1751/1751]\n",
      "\n",
      "--2022-12-06 15:22:23--  https://raw.githubusercontent.com/nvidia/NeMo/master/examples/tts/conf/fastpitch_align_v1.05.yaml\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6831 (6.7K) [text/plain]\n",
      "Saving to: ‘fastpitch_align_v1.05.yaml.1’\n",
      "\n",
      "fastpitch_align_v1. 100%[===================>]   6.67K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-12-06 15:22:24 (104 MB/s) - ‘fastpitch_align_v1.05.yaml.1’ saved [6831/6831]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/nvidia/NeMo/$BRANCH/examples/tts/fastpitch_finetune.py\n",
    "\n",
    "!mkdir -p conf \\\n",
    "&& cd conf \\\n",
    "&& wget https://raw.githubusercontent.com/nvidia/NeMo/$BRANCH/examples/tts/conf/fastpitch_align_v1.05.yaml \\\n",
    "&& cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc6d3a2-e954-4426-b8c8-e69030a2c42d",
   "metadata": {},
   "source": [
    "We also need some additional files (see `FastPitch_MixerTTS_Training.ipynb` tutorial for more details) for training. Let's download these, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "20374059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-06 15:22:25--  https://raw.githubusercontent.com/NVIDIA/NeMo/master/scripts/tts_dataset_files/cmudict-0.7b_nv22.10\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3741429 (3.6M) [text/plain]\n",
      "Saving to: ‘cmudict-0.7b_nv22.10’\n",
      "\n",
      "cmudict-0.7b_nv22.1 100%[===================>]   3.57M  --.-KB/s    in 0.07s   \n",
      "\n",
      "2022-12-06 15:22:25 (52.1 MB/s) - ‘cmudict-0.7b_nv22.10’ saved [3741429/3741429]\n",
      "\n",
      "--2022-12-06 15:22:25--  https://raw.githubusercontent.com/NVIDIA/NeMo/master/scripts/tts_dataset_files/heteronyms-052722\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1606 (1.6K) [text/plain]\n",
      "Saving to: ‘heteronyms-052722’\n",
      "\n",
      "heteronyms-052722   100%[===================>]   1.57K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-12-06 15:22:25 (47.9 MB/s) - ‘heteronyms-052722’ saved [1606/1606]\n",
      "\n",
      "--2022-12-06 15:22:25--  https://raw.githubusercontent.com/NVIDIA/NeMo/master/nemo_text_processing/text_normalization/en/data/whitelist/lj_speech.tsv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 263 [text/plain]\n",
      "Saving to: ‘lj_speech.tsv’\n",
      "\n",
      "lj_speech.tsv       100%[===================>]     263  --.-KB/s    in 0s      \n",
      "\n",
      "2022-12-06 15:22:25 (25.1 MB/s) - ‘lj_speech.tsv’ saved [263/263]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# additional files\n",
    "!mkdir -p tts_dataset_files && cd tts_dataset_files \\\n",
    "&& wget https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/scripts/tts_dataset_files/cmudict-0.7b_nv22.10 \\\n",
    "&& wget https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/scripts/tts_dataset_files/heteronyms-052722 \\\n",
    "&& wget https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/nemo_text_processing/text_normalization/en/data/whitelist/lj_speech.tsv \\\n",
    "&& cd .."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

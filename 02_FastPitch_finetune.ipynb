{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea801208-e8e3-47d4-b099-ac2e952e4b4a",
   "metadata": {
    "id": "ef75d1d5"
   },
   "source": [
    "## Finetuning FastPitch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80c8066-a8eb-48c3-bd0d-dbda23094bdb",
   "metadata": {
    "id": "lhhg2wBNtW0r"
   },
   "source": [
    "Let's also download the pretrained checkpoint that we want to finetune from. NeMo will save checkpoints to `~/.cache`, so let's move that to our current directory. \n",
    "\n",
    "*Note: please, check that `home_path` refers to your home folder. Otherwise, change it manually.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b12bff96-7ed5-4a06-8e70-3fd7e40b9eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEAKER_ID = \"9017\"\n",
    "MODEL_NAME = \"tts_en_fastpitch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d541abfc-2a2d-4168-8434-5d6f15fbe30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tcapelle\n"
     ]
    }
   ],
   "source": [
    "home_path = !(echo $HOME)\n",
    "home_path = home_path[0]\n",
    "print(home_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653ea613-c122-459b-902d-96d07179299c",
   "metadata": {
    "id": "lhhg2wBNtW0r"
   },
   "source": [
    "Let's also download the pretrained checkpoint that we want to finetune from. NeMo will save checkpoints to `~/.cache`, so let's move that to our current directory. \n",
    "\n",
    "*Note: please, check that `home_path` refers to your home folder. Otherwise, change it manually.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "716e8666-ca68-4e1e-82cc-5d4d1892e8f2",
   "metadata": {
    "id": "LggELooctXCT",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import IPython.display as ipd\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from nemo.collections.tts.models import FastPitchModel\n",
    "FastPitchModel.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a31b138-dc2b-4e42-91ec-80d08e064192",
   "metadata": {
    "id": "LggELooctXCT",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying /home/tcapelle/.cache/torch/NeMo/NeMo_1.12.0/tts_en_fastpitch_align/26d7e09971f1d611e24df90c7a9d9b38/tts_en_fastpitch_align.nemo to ./\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "187023360"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nemo_files = [p for p in Path(f\"{home_path}/.cache/torch/NeMo/\").glob(f\"**/{MODEL_NAME}_align.nemo\")]\n",
    "print(f\"Copying {nemo_files[0]} to ./\")\n",
    "Path(f\"./{MODEL_NAME}_align.nemo\").write_bytes(nemo_files[0].read_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edd0b5e3-b331-48ba-81e0-59f7b572d22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/tcapelle/.cache/torch/NeMo/NeMo_1.12.0/tts_en_fastpitch_align/26d7e09971f1d611e24df90c7a9d9b38/tts_en_fastpitch_align.nemo')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nemo_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dac038-c59c-46c3-94e3-15419d0666e2",
   "metadata": {
    "id": "12b5511c"
   },
   "source": [
    "We can now train our model with the following command:\n",
    "\n",
    "**NOTE: This will take about 50 minutes on colab's K80 GPUs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c348d955-988d-47aa-807b-b50d860efe21",
   "metadata": {
    "id": "reY1LV4lwWoq",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-06 16:38:10 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2022-12-06 16:38:11 experimental:27] Module <class 'nemo_text_processing.g2p.modules.IPAG2P'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-06 16:38:11 experimental:27] Module <class 'nemo.collections.common.tokenizers.text_to_speech.tts_tokenizers.IPATokenizer'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-06 16:38:11 experimental:27] Module <class 'nemo.collections.common.tokenizers.text_to_speech.tts_tokenizers.PhonemizerTokenizer'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-06 16:38:11 experimental:27] Module <class 'nemo.collections.tts.models.radtts.RadTTSModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2022-12-06 16:38:12 exp_manager:291] Experiments will be logged at fastpitch_finetune/FastPitch/2022-12-06_16-38-12\n",
      "[NeMo I 2022-12-06 16:38:12 exp_manager:669] TensorboardLogger has been set up\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcapecape\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./fastpitch_finetune/wandb/run-20221206_163813-2022-12-06_16-38-12\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m2022-12-06_16-38-12\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/capecape/nemo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/capecape/nemo/runs/2022-12-06_16-38-12\u001b[0m\n",
      "[NeMo I 2022-12-06 16:38:18 exp_manager:684] WandBLogger has been set up\n",
      "[NeMo W 2022-12-06 16:38:18 nemo_logging:349] /home/tcapelle/mambaforge/envs/nemo/lib/python3.9/site-packages/pytorch_lightning/loggers/logger.py:229: LightningDeprecationWarning: `LoggerCollection` is deprecated in v1.6 and will be removed in v1.8. Directly pass a list of loggers to the Trainer and access the list via the `trainer.loggers` attribute.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "[NeMo W 2022-12-06 16:38:18 nemo_logging:349] /home/tcapelle/mambaforge/envs/nemo/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:2274: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.\n",
      "      rank_zero_deprecation(\"`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.\")\n",
      "    \n",
      "[NeMo W 2022-12-06 16:38:18 exp_manager:919] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 1000. Please ensure that max_steps will run for at least 25 epochs to ensure that checkpointing will not error out.\n",
      "[NeMo I 2022-12-06 16:38:21 tokenize_and_classify:87] Creating ClassifyFst grammars.\n",
      "[NeMo W 2022-12-06 16:38:50 modules:88] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n",
      "[NeMo I 2022-12-06 16:38:51 data:215] Loading dataset from 9017_manifest_train_local.json.\n",
      "76it [00:00, 130481.83it/s]\n",
      "[NeMo I 2022-12-06 16:38:51 data:252] Loaded dataset with 76 files.\n",
      "[NeMo I 2022-12-06 16:38:51 data:254] Dataset contains 0.08 hours.\n",
      "[NeMo I 2022-12-06 16:38:51 data:356] Pruned 0 files. Final dataset contains 76 files\n",
      "[NeMo I 2022-12-06 16:38:51 data:358] Pruned 0.00 hours. Final dataset contains 0.08 hours.\n",
      "[NeMo I 2022-12-06 16:38:51 data:215] Loading dataset from 9017_manifest_valid_local.json.\n",
      "2it [00:00, 8621.39it/s]\n",
      "[NeMo I 2022-12-06 16:38:51 data:252] Loaded dataset with 2 files.\n",
      "[NeMo I 2022-12-06 16:38:51 data:254] Dataset contains 0.00 hours.\n",
      "[NeMo I 2022-12-06 16:38:51 data:356] Pruned 0 files. Final dataset contains 2 files\n",
      "[NeMo I 2022-12-06 16:38:51 data:358] Pruned 0.00 hours. Final dataset contains 0.00 hours.\n",
      "[NeMo I 2022-12-06 16:38:51 features:225] PADDING: 1\n",
      "[NeMo I 2022-12-06 16:38:54 tokenize_and_classify:87] Creating ClassifyFst grammars.\n"
     ]
    }
   ],
   "source": [
    "!(python fastpitch_finetune.py --config-name=fastpitch_align_v1.05.yaml \\\n",
    "  train_dataset=9017_manifest_train_local.json \\\n",
    "  validation_datasets=9017_manifest_valid_local.json \\\n",
    "  exp_manager.exp_dir=./fastpitch_finetune \\\n",
    "  +exp_manager.create_wandb_logger=True \\\n",
    "  +exp_manager.wandb_logger_kwargs='{project:nemo, job_type:training, log_model:True}' \\\n",
    "  +init_from_nemo_model=./tts_en_fastpitch_align.nemo \\\n",
    "  model.pitch_mean=121.9 model.pitch_std=23.1 \\\n",
    "  model.pitch_fmin=30 model.pitch_fmax=512 \\\n",
    "  trainer.max_steps=1000 \\\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a64ef3-3382-4e4a-b23e-0a1f857f9b96",
   "metadata": {
    "id": "j2svKvd1eMhf"
   },
   "source": [
    "Let's take a closer look at the training command:\n",
    "\n",
    "* `--config-name=fastpitch_align_v1.05.yaml`\n",
    "  * We first tell the script what config file to use.\n",
    "\n",
    "* `train_dataset=./6097_manifest_train_dur_5_mins_local.json \n",
    "  validation_datasets=./6097_manifest_dev_ns_all_local.json \n",
    "  sup_data_path=./fastpitch_sup_data`\n",
    "  * We tell the script what manifest files to train and eval on, as well as where supplementary data is located (or will be calculated and saved during training if not provided).\n",
    "  \n",
    "* `phoneme_dict_path=tts_dataset_files/cmudict-0.7b_nv22.10 \n",
    "heteronyms_path=tts_dataset_files/heteronyms-052722\n",
    "whitelist_path=tts_dataset_files/lj_speech.tsv \n",
    "`\n",
    "  * We tell the script where `phoneme_dict_path`, `heteronyms-052722` and `whitelist_path` are located. These are the additional files we downloaded earlier, and are used in preprocessing the data.\n",
    "  \n",
    "* `exp_manager.exp_dir=./ljspeech_to_6097_no_mixing_5_mins`\n",
    "  * Where we want to save our log files, tensorboard file, checkpoints, and more.\n",
    "\n",
    "* `+init_from_nemo_model=./tts_en_fastpitch_align.nemo`\n",
    "  * We tell the script what checkpoint to finetune from.\n",
    "\n",
    "* `+trainer.max_steps=1000 ~trainer.max_epochs trainer.check_val_every_n_epoch=25`\n",
    "  * For this experiment, we tell the script to train for 1000 training steps/iterations rather than specifying a number of epochs to run. Since the config file specifies `max_epochs` instead, we need to remove that using `~trainer.max_epochs`.\n",
    "\n",
    "* `model.train_ds.dataloader_params.batch_size=24 model.validation_ds.dataloader_params.batch_size=24`\n",
    "  * Set batch sizes for the training and validation data loaders.\n",
    "\n",
    "* `model.n_speakers=1`\n",
    "  * The number of speakers in the data. There is only 1 for now, but we will revisit this parameter later in the notebook.\n",
    "\n",
    "* `model.pitch_mean=121.9 model.pitch_std=23.1 model.pitch_fmin=30 model.pitch_fmax=512`\n",
    "  * For the new speaker, we need to define new pitch hyperparameters for better audio quality.\n",
    "  * These parameters work for speaker 6097 from the Hi-Fi TTS dataset.\n",
    "  * For speaker 92, we suggest `model.pitch_mean=214.5 model.pitch_std=30.9 model.pitch_fmin=80 model.pitch_fmax=512`.\n",
    "  * fmin and fmax are hyperparameters to librosa's pyin function. We recommend tweaking these per speaker.\n",
    "  * After fmin and fmax are defined, pitch mean and std can be easily extracted.\n",
    "\n",
    "* `model.optim.lr=2e-4 ~model.optim.sched model.optim.name=adam`\n",
    "  * For fine-tuning, we lower the learning rate.\n",
    "  * We use a fixed learning rate of 2e-4.\n",
    "  * We switch from the lamb optimizer to the adam optimizer.\n",
    "\n",
    "* `trainer.devices=1 trainer.strategy=null`\n",
    "  * For this notebook, we default to 1 gpu which means that we do not need ddp.\n",
    "  * If you have the compute resources, feel free to scale this up to the number of free gpus you have available.\n",
    "  * Please remove the `trainer.strategy=null` section if you intend on multi-gpu training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9903bb-9713-4900-beef-8c1f6d6e56ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

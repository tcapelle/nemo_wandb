{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea801208-e8e3-47d4-b099-ac2e952e4b4a",
   "metadata": {
    "id": "ef75d1d5"
   },
   "source": [
    "## Finetuning FastPitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321fdfb6-0ce1-46d9-a48f-77f071e2feb3",
   "metadata": {
    "id": "LggELooctXCT",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80c8066-a8eb-48c3-bd0d-dbda23094bdb",
   "metadata": {
    "id": "lhhg2wBNtW0r"
   },
   "source": [
    "Let's also download the pretrained checkpoint that we want to finetune from. NeMo will save checkpoints to `~/.cache`, so let's move that to our current directory. \n",
    "\n",
    "*Note: please, check that `home_path` refers to your home folder. Otherwise, change it manually.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b12bff96-7ed5-4a06-8e70-3fd7e40b9eec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPEAKER_ID = \"9017\"\n",
    "MODEL_NAME = \"tts_en_fastpitch\"\n",
    "\n",
    "WANDB_PROJECT = \"tts-workshop\"\n",
    "WANDB_ENTITY = \"capecape\" # replace with your wandb username or team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b7bc11-2d34-4f4a-99c6-fb8e125bc8a1",
   "metadata": {},
   "source": [
    "Let's download the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f3d986-3b44-4e3a-a0da-88e4a5fa0a9c",
   "metadata": {
    "id": "LggELooctXCT",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-07 11:28:28 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2022-12-07 11:28:28 experimental:27] Module <class 'nemo_text_processing.g2p.modules.IPAG2P'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-07 11:28:28 experimental:27] Module <class 'nemo.collections.common.tokenizers.text_to_speech.tts_tokenizers.IPATokenizer'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-07 11:28:28 experimental:27] Module <class 'nemo.collections.common.tokenizers.text_to_speech.tts_tokenizers.PhonemizerTokenizer'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-07 11:28:28 experimental:27] Module <class 'nemo.collections.tts.models.radtts.RadTTSModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-07 11:28:28 cloud:56] Found existing object /home/tcapelle/.cache/torch/NeMo/NeMo_1.12.0/tts_en_fastpitch_align/26d7e09971f1d611e24df90c7a9d9b38/tts_en_fastpitch_align.nemo.\n",
      "[NeMo I 2022-12-07 11:28:28 cloud:62] Re-using file from: /home/tcapelle/.cache/torch/NeMo/NeMo_1.12.0/tts_en_fastpitch_align/26d7e09971f1d611e24df90c7a9d9b38/tts_en_fastpitch_align.nemo\n",
      "[NeMo I 2022-12-07 11:28:28 common:910] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-12-07 11:28:32 tokenize_and_classify:87] Creating ClassifyFst grammars.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-07 11:29:04 modules:88] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n",
      "[NeMo W 2022-12-07 11:29:04 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.torch.data.TTSDataset\n",
      "      manifest_filepath: /ws/LJSpeech/nvidia_ljspeech_train_clean_ngc.json\n",
      "      sample_rate: 22050\n",
      "      sup_data_path: /raid/LJSpeech/supplementary\n",
      "      sup_data_types:\n",
      "      - align_prior_matrix\n",
      "      - pitch\n",
      "      n_fft: 1024\n",
      "      win_length: 1024\n",
      "      hop_length: 256\n",
      "      window: hann\n",
      "      n_mels: 80\n",
      "      lowfreq: 0\n",
      "      highfreq: 8000\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      ignore_file: null\n",
      "      trim: false\n",
      "      pitch_fmin: 65.40639132514966\n",
      "      pitch_fmax: 2093.004522404789\n",
      "      pitch_norm: true\n",
      "      pitch_mean: 212.35873413085938\n",
      "      pitch_std: 68.52806091308594\n",
      "      use_beta_binomial_interpolator: true\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: true\n",
      "      batch_size: 24\n",
      "      num_workers: 0\n",
      "    \n",
      "[NeMo W 2022-12-07 11:29:04 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.torch.data.TTSDataset\n",
      "      manifest_filepath: /ws/LJSpeech/nvidia_ljspeech_val_clean_ngc.json\n",
      "      sample_rate: 22050\n",
      "      sup_data_path: /raid/LJSpeech/supplementary\n",
      "      sup_data_types:\n",
      "      - align_prior_matrix\n",
      "      - pitch\n",
      "      n_fft: 1024\n",
      "      win_length: 1024\n",
      "      hop_length: 256\n",
      "      window: hann\n",
      "      n_mels: 80\n",
      "      lowfreq: 0\n",
      "      highfreq: 8000\n",
      "      max_duration: null\n",
      "      min_duration: null\n",
      "      ignore_file: null\n",
      "      trim: false\n",
      "      pitch_fmin: 65.40639132514966\n",
      "      pitch_fmax: 2093.004522404789\n",
      "      pitch_norm: true\n",
      "      pitch_mean: 212.35873413085938\n",
      "      pitch_std: 68.52806091308594\n",
      "      use_beta_binomial_interpolator: true\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 24\n",
      "      num_workers: 0\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-07 11:29:05 features:225] PADDING: 1\n",
      "[NeMo I 2022-12-07 11:29:07 save_restore_connector:243] Model FastPitchModel was successfully restored from /home/tcapelle/.cache/torch/NeMo/NeMo_1.12.0/tts_en_fastpitch_align/26d7e09971f1d611e24df90c7a9d9b38/tts_en_fastpitch_align.nemo.\n"
     ]
    }
   ],
   "source": [
    "from nemo.collections.tts.models import FastPitchModel\n",
    "FastPitchModel.from_pretrained(MODEL_NAME);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c62728-0b7f-404b-831d-50d80bd6dcab",
   "metadata": {
    "id": "lhhg2wBNtW0r"
   },
   "source": [
    "We will copy the model to our current working dir for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ed70f0b-6651-4997-b755-e63b93987301",
   "metadata": {
    "id": "LggELooctXCT",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying /home/tcapelle/.cache/torch/NeMo/NeMo_1.12.0/tts_en_fastpitch_align/26d7e09971f1d611e24df90c7a9d9b38/tts_en_fastpitch_align.nemo to ./tts_en_fastpitch_align.nemo\n"
     ]
    }
   ],
   "source": [
    "for nemo_file in (Path.home()/\".cache/torch/NeMo/\").glob(f\"**/{MODEL_NAME}_align.nemo\"):\n",
    "    print(f\"Copying {nemo_file} to ./{nemo_file.name}\")\n",
    "    Path(f\"./{nemo_file.name}\").write_bytes(nemo_file.read_bytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dac038-c59c-46c3-94e3-15419d0666e2",
   "metadata": {
    "id": "12b5511c"
   },
   "source": [
    "## Train Time!\n",
    "\n",
    "We can now train our model with the following command:\n",
    "\n",
    "**NOTE: This will take about 50 minutes on colab's K80 GPUs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c348d955-988d-47aa-807b-b50d860efe21",
   "metadata": {
    "id": "reY1LV4lwWoq",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-07 11:29:11 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2022-12-07 11:29:12 experimental:27] Module <class 'nemo_text_processing.g2p.modules.IPAG2P'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-07 11:29:12 experimental:27] Module <class 'nemo.collections.common.tokenizers.text_to_speech.tts_tokenizers.IPATokenizer'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-07 11:29:12 experimental:27] Module <class 'nemo.collections.common.tokenizers.text_to_speech.tts_tokenizers.PhonemizerTokenizer'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-07 11:29:12 experimental:27] Module <class 'nemo.collections.tts.models.radtts.RadTTSModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2022-12-07 11:29:12 exp_manager:291] Experiments will be logged at fastpitch_finetune/FastPitch/2022-12-07_11-29-12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcapecape\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./fastpitch_finetune/wandb/run-20221207_112914-2022-12-07_11-29-12\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m2022-12-07_11-29-12\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/capecape/tts-workshop\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/capecape/tts-workshop/runs/2022-12-07_11-29-12\u001b[0m\n",
      "[NeMo I 2022-12-07 11:29:19 exp_manager:684] WandBLogger has been set up\n",
      "[NeMo W 2022-12-07 11:29:19 nemo_logging:349] /home/tcapelle/mambaforge/envs/nemo/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:2274: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.\n",
      "      rank_zero_deprecation(\"`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.\")\n",
      "    \n",
      "[NeMo W 2022-12-07 11:29:19 exp_manager:919] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 100. Please ensure that max_steps will run for at least 10 epochs to ensure that checkpointing will not error out.\n",
      "[NeMo I 2022-12-07 11:29:21 tokenize_and_classify:87] Creating ClassifyFst grammars.\n",
      "[NeMo W 2022-12-07 11:29:53 modules:88] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n",
      "[NeMo I 2022-12-07 11:29:53 data:215] Loading dataset from 9017_manifest_train_local.json.\n",
      "76it [00:00, 132543.49it/s]\n",
      "[NeMo I 2022-12-07 11:29:53 data:252] Loaded dataset with 76 files.\n",
      "[NeMo I 2022-12-07 11:29:53 data:254] Dataset contains 0.08 hours.\n",
      "[NeMo I 2022-12-07 11:29:53 data:356] Pruned 0 files. Final dataset contains 76 files\n",
      "[NeMo I 2022-12-07 11:29:53 data:358] Pruned 0.00 hours. Final dataset contains 0.08 hours.\n",
      "[NeMo I 2022-12-07 11:29:53 data:215] Loading dataset from 9017_manifest_valid_local.json.\n",
      "2it [00:00, 14820.86it/s]\n",
      "[NeMo I 2022-12-07 11:29:53 data:252] Loaded dataset with 2 files.\n",
      "[NeMo I 2022-12-07 11:29:53 data:254] Dataset contains 0.00 hours.\n",
      "[NeMo I 2022-12-07 11:29:53 data:356] Pruned 0 files. Final dataset contains 2 files\n",
      "[NeMo I 2022-12-07 11:29:53 data:358] Pruned 0.00 hours. Final dataset contains 0.00 hours.\n",
      "[NeMo I 2022-12-07 11:29:53 features:225] PADDING: 1\n",
      "[NeMo I 2022-12-07 11:29:57 tokenize_and_classify:87] Creating ClassifyFst grammars.\n",
      "[NeMo W 2022-12-07 11:30:30 modules:88] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n",
      "[NeMo W 2022-12-07 11:30:30 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.torch.data.TTSDataset\n",
      "      manifest_filepath: /ws/LJSpeech/nvidia_ljspeech_train_clean_ngc.json\n",
      "      sample_rate: 22050\n",
      "      sup_data_path: /raid/LJSpeech/supplementary\n",
      "      sup_data_types:\n",
      "      - align_prior_matrix\n",
      "      - pitch\n",
      "      n_fft: 1024\n",
      "      win_length: 1024\n",
      "      hop_length: 256\n",
      "      window: hann\n",
      "      n_mels: 80\n",
      "      lowfreq: 0\n",
      "      highfreq: 8000\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      ignore_file: null\n",
      "      trim: false\n",
      "      pitch_fmin: 65.40639132514966\n",
      "      pitch_fmax: 2093.004522404789\n",
      "      pitch_norm: true\n",
      "      pitch_mean: 212.35873413085938\n",
      "      pitch_std: 68.52806091308594\n",
      "      use_beta_binomial_interpolator: true\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: true\n",
      "      batch_size: 24\n",
      "      num_workers: 0\n",
      "    \n",
      "[NeMo W 2022-12-07 11:30:30 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.torch.data.TTSDataset\n",
      "      manifest_filepath: /ws/LJSpeech/nvidia_ljspeech_val_clean_ngc.json\n",
      "      sample_rate: 22050\n",
      "      sup_data_path: /raid/LJSpeech/supplementary\n",
      "      sup_data_types:\n",
      "      - align_prior_matrix\n",
      "      - pitch\n",
      "      n_fft: 1024\n",
      "      win_length: 1024\n",
      "      hop_length: 256\n",
      "      window: hann\n",
      "      n_mels: 80\n",
      "      lowfreq: 0\n",
      "      highfreq: 8000\n",
      "      max_duration: null\n",
      "      min_duration: null\n",
      "      ignore_file: null\n",
      "      trim: false\n",
      "      pitch_fmin: 65.40639132514966\n",
      "      pitch_fmax: 2093.004522404789\n",
      "      pitch_norm: true\n",
      "      pitch_mean: 212.35873413085938\n",
      "      pitch_std: 68.52806091308594\n",
      "      use_beta_binomial_interpolator: true\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 24\n",
      "      num_workers: 0\n",
      "    \n",
      "[NeMo I 2022-12-07 11:30:30 features:225] PADDING: 1\n",
      "[NeMo I 2022-12-07 11:30:31 save_restore_connector:243] Model FastPitchModel was successfully restored from /home/tcapelle/wandb/nvidia-workshop/tts_en_fastpitch_align.nemo.\n",
      "[NeMo I 2022-12-07 11:30:31 modelPT:1059] Model checkpoint restored from nemo file with path : `./tts_en_fastpitch_align.nemo`\n",
      "[NeMo W 2022-12-07 11:30:31 nemo_logging:349] /home/tcapelle/mambaforge/envs/nemo/lib/python3.9/site-packages/pytorch_lightning/callbacks/base.py:22: LightningDeprecationWarning: pytorch_lightning.callbacks.base.Callback has been deprecated in v1.7 and will be removed in v1.9. Use the equivalent class from the pytorch_lightning.callbacks.callback.Callback class instead.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo I 2022-12-07 11:30:32 modelPT:597] Optimizer config = Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.999]\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: False\n",
      "        lr: 0.0002\n",
      "        maximize: False\n",
      "        weight_decay: 1e-06\n",
      "    )\n",
      "[NeMo I 2022-12-07 11:30:32 lr_scheduler:772] Scheduler not initialized as no `sched` config supplied to setup_optimizer()\n",
      "\n",
      "  | Name             | Type                              | Params\n",
      "-----------------------------------------------------------------------\n",
      "0 | mel_loss         | MelLoss                           | 0     \n",
      "1 | pitch_loss       | PitchLoss                         | 0     \n",
      "2 | duration_loss    | DurationLoss                      | 0     \n",
      "3 | aligner          | AlignmentEncoder                  | 1.0 M \n",
      "4 | forward_sum_loss | ForwardSumLoss                    | 0     \n",
      "5 | bin_loss         | BinLoss                           | 0     \n",
      "6 | preprocessor     | AudioToMelSpectrogramPreprocessor | 0     \n",
      "7 | fastpitch        | FastPitchModule                   | 45.8 M\n",
      "-----------------------------------------------------------------------\n",
      "45.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "45.8 M    Total params\n",
      "91.518    Total estimated model params size (MB)\n",
      "[NeMo W 2022-12-07 11:30:39 nemo_logging:349] /home/tcapelle/mambaforge/envs/nemo/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1892: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "      rank_zero_warn(\n",
      "    \n",
      "Epoch 9:  80%|████████████▊   | 4/5 [00:01<00:00,  2.39it/s, loss=4, v_num=9-12]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|████████████████| 5/5 [00:02<00:00,  2.28it/s, loss=4, v_num=9-12]\u001b[A\n",
      "                                                                                \u001b[AEpoch 9, global step 40: 'val_loss' reached 1.88479 (best 1.88479), saving model to '/home/tcapelle/wandb/nvidia-workshop/fastpitch_finetune/FastPitch/2022-12-07_11-29-12/checkpoints/FastPitch--val_loss=1.8848-epoch=9.ckpt' as top 3\n",
      "Epoch 19:  80%|█████████▌  | 4/5 [00:01<00:00,  2.14it/s, loss=3.27, v_num=9-12]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19: 100%|████████████| 5/5 [00:02<00:00,  2.08it/s, loss=3.27, v_num=9-12]\u001b[A\n",
      "                                                                                \u001b[AEpoch 19, global step 80: 'val_loss' reached 1.85754 (best 1.85754), saving model to '/home/tcapelle/wandb/nvidia-workshop/fastpitch_finetune/FastPitch/2022-12-07_11-29-12/checkpoints/FastPitch--val_loss=1.8575-epoch=19.ckpt' as top 3\n",
      "Epoch 24: 100%|████████████| 4/4 [00:01<00:00,  2.34it/s, loss=3.19, v_num=9-12]`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Epoch 24: 100%|████████████| 4/4 [00:01<00:00,  2.34it/s, loss=3.19, v_num=9-12]\n",
      "Error executing job with overrides: ['train_dataset=9017_manifest_train_local.json', 'validation_datasets=9017_manifest_valid_local.json', 'exp_manager.exp_dir=./fastpitch_finetune', '+exp_manager.create_wandb_logger=True', '+exp_manager.wandb_logger_kwargs={project:tts-workshop, job_type:training, log_model:True}', '+init_from_nemo_model=./tts_en_fastpitch_align.nemo', 'model.pitch_mean=152.3', 'model.pitch_std=64.0', 'model.pitch_fmin=30', 'model.pitch_fmax=512', 'trainer.max_steps=100']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tcapelle/wandb/nvidia-workshop/fastpitch_finetune.py\", line 37, in main\n",
      "    trainer.fit(model)\n",
      "  File \"/home/tcapelle/mambaforge/envs/nemo/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 696, in fit\n",
      "    self._call_and_handle_interrupt(\n",
      "  File \"/home/tcapelle/mambaforge/envs/nemo/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/tcapelle/mambaforge/envs/nemo/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/home/tcapelle/mambaforge/envs/nemo/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1180, in _run\n",
      "    self._call_teardown_hook()\n",
      "  File \"/home/tcapelle/mambaforge/envs/nemo/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1486, in _call_teardown_hook\n",
      "    logger.finalize(\"success\")\n",
      "  File \"/home/tcapelle/mambaforge/envs/nemo/lib/python3.9/site-packages/pytorch_lightning/utilities/rank_zero.py\", line 32, in wrapped_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/tcapelle/mambaforge/envs/nemo/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py\", line 488, in finalize\n",
      "    self._scan_and_log_checkpoints(self._checkpoint_callback)\n",
      "  File \"/home/tcapelle/mambaforge/envs/nemo/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py\", line 533, in _scan_and_log_checkpoints\n",
      "    artifact = wandb.Artifact(name=f\"model-{self.experiment.id}\", type=\"model\", metadata=metadata)\n",
      "  File \"/home/tcapelle/mambaforge/envs/nemo/lib/python3.9/site-packages/wandb/sdk/wandb_artifacts.py\", line 164, in __init__\n",
      "    metadata = _normalize_metadata(metadata)\n",
      "  File \"/home/tcapelle/mambaforge/envs/nemo/lib/python3.9/site-packages/wandb/sdk/wandb_artifacts.py\", line 98, in _normalize_metadata\n",
      "    Dict[str, Any], json.loads(json.dumps(util.make_safe_for_json(metadata)))\n",
      "  File \"/home/tcapelle/mambaforge/envs/nemo/lib/python3.9/json/__init__.py\", line 231, in dumps\n",
      "    return _default_encoder.encode(obj)\n",
      "  File \"/home/tcapelle/mambaforge/envs/nemo/lib/python3.9/json/encoder.py\", line 199, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "  File \"/home/tcapelle/mambaforge/envs/nemo/lib/python3.9/json/encoder.py\", line 257, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "  File \"/home/tcapelle/mambaforge/envs/nemo/lib/python3.9/json/encoder.py\", line 179, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type Tensor is not JSON serializable\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  epoch ▁▂▃▃▃▄▅▆▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             epoch_time ▁▂▁▁▂▁▂▁▁▇▁▁▁▁▁▁▁▂▁█▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                lr-Adam ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             t_bin_loss ▁▁▃▃▃▃▅▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             t_ctc_loss ██▅▅▂▁▃▂▃▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             t_dur_loss █▆▅▃▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 t_loss █▆▄▄▂▁▂▁▂▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             t_mel_loss █▅▄▃▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           t_pitch_loss █▆▅▂▃▁▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_backward_timing ▅▄█▁▅▄▅▃▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      train_step_timing ▄▃█▁▄▃▄▂█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    trainer/global_step ▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val_dur_loss ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               val_loss █▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val_mel_loss █▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_pitch_loss █▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: validation_step_timing ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             epoch_time 1.70565\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                lr-Adam 0.0002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             t_bin_loss 0.2485\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             t_ctc_loss 3.0896\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             t_dur_loss 0.00981\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 t_loss 3.85558\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             t_mel_loss 0.49462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           t_pitch_loss 0.01307\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_backward_timing 0.04272\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      train_step_timing 0.11584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    trainer/global_step 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val_dur_loss 0.0286\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               val_loss 1.85754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val_mel_loss 1.76242\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_pitch_loss 0.06652\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: validation_step_timing 0.05109\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33m2022-12-07_11-29-12\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/capecape/tts-workshop/runs/2022-12-07_11-29-12\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./fastpitch_finetune/wandb/run-20221207_112914-2022-12-07_11-29-12/logs\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!(python fastpitch_finetune.py --config-name=fastpitch_align_v1.05.yaml \\\n",
    "  train_dataset=9017_manifest_train_local.json \\\n",
    "  validation_datasets=9017_manifest_valid_local.json \\\n",
    "  exp_manager.exp_dir=./fastpitch_finetune \\\n",
    "  +exp_manager.create_wandb_logger=True \\\n",
    "  +exp_manager.wandb_logger_kwargs='{project:tts-workshop, job_type:training, log_model:True}' \\\n",
    "  +init_from_nemo_model=./tts_en_fastpitch_align.nemo \\\n",
    "  model.pitch_mean=152.3 model.pitch_std=64.0 \\\n",
    "  model.pitch_fmin=30 model.pitch_fmax=512 \\\n",
    "  trainer.max_steps=100 \\\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a64ef3-3382-4e4a-b23e-0a1f857f9b96",
   "metadata": {
    "id": "j2svKvd1eMhf"
   },
   "source": [
    "Let's take a closer look at the training command:\n",
    "\n",
    "* `--config-name=fastpitch_align_v1.05.yaml`\n",
    "  * We first tell the script what config file to use.\n",
    "\n",
    "* `train_dataset=./6097_manifest_train_dur_5_mins_local.json \n",
    "  validation_datasets=./6097_manifest_dev_ns_all_local.json \n",
    "  sup_data_path=./fastpitch_sup_data`\n",
    "  * We tell the script what manifest files to train and eval on, as well as where supplementary data is located (or will be calculated and saved during training if not provided).\n",
    "  \n",
    "* `phoneme_dict_path=tts_dataset_files/cmudict-0.7b_nv22.10 \n",
    "heteronyms_path=tts_dataset_files/heteronyms-052722\n",
    "whitelist_path=tts_dataset_files/lj_speech.tsv \n",
    "`\n",
    "  * We tell the script where `phoneme_dict_path`, `heteronyms-052722` and `whitelist_path` are located. These are the additional files we downloaded earlier, and are used in preprocessing the data.\n",
    "  \n",
    "* `exp_manager.exp_dir=./ljspeech_to_6097_no_mixing_5_mins`\n",
    "  * Where we want to save our log files, tensorboard file, checkpoints, and more.\n",
    "\n",
    "* `+init_from_nemo_model=./tts_en_fastpitch_align.nemo`\n",
    "  * We tell the script what checkpoint to finetune from.\n",
    "\n",
    "* `+trainer.max_steps=1000 ~trainer.max_epochs trainer.check_val_every_n_epoch=25`\n",
    "  * For this experiment, we tell the script to train for 1000 training steps/iterations rather than specifying a number of epochs to run. Since the config file specifies `max_epochs` instead, we need to remove that using `~trainer.max_epochs`.\n",
    "\n",
    "* `model.train_ds.dataloader_params.batch_size=24 model.validation_ds.dataloader_params.batch_size=24`\n",
    "  * Set batch sizes for the training and validation data loaders.\n",
    "\n",
    "* `model.n_speakers=1`\n",
    "  * The number of speakers in the data. There is only 1 for now, but we will revisit this parameter later in the notebook.\n",
    "\n",
    "* `model.pitch_mean=152.3 model.pitch_std=64.0 model.pitch_fmin=30 model.pitch_fmax=512`\n",
    "  * For the new speaker, we need to define new pitch hyperparameters for better audio quality.\n",
    "  * These parameters work for speaker 9017 from the Hi-Fi TTS dataset.\n",
    "  * fmin and fmax are hyperparameters to librosa's pyin function. We recommend tweaking these per speaker.\n",
    "  * After fmin and fmax are defined, pitch mean and std can be easily extracted.\n",
    "\n",
    "* `model.optim.lr=2e-4 ~model.optim.sched model.optim.name=adam`\n",
    "  * For fine-tuning, we lower the learning rate.\n",
    "  * We use a fixed learning rate of 2e-4.\n",
    "  * We switch from the lamb optimizer to the adam optimizer.\n",
    "\n",
    "* `trainer.devices=1 trainer.strategy=null`\n",
    "  * For this notebook, we default to 1 gpu which means that we do not need ddp.\n",
    "  * If you have the compute resources, feel free to scale this up to the number of free gpus you have available.\n",
    "  * Please remove the `trainer.strategy=null` section if you intend on multi-gpu training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9497baa7-e87a-47e6-a4f9-3e631a67f9e1",
   "metadata": {
    "id": "c3bdf1ed"
   },
   "source": [
    "## Synthesize Samples from Finetuned Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c3b08d-c201-4ba5-b34e-b325eafe11f6",
   "metadata": {
    "id": "f2b46325"
   },
   "source": [
    "Once we have finetuned our FastPitch model, we can synthesize the audio samples for given text using the following inference steps. We use a HiFi-GAN vocoder trained on LJSpeech.\n",
    "\n",
    "We define some helper functions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3e0db1a-0f9a-476f-926a-0f2307de2f65",
   "metadata": {
    "id": "886c91dc"
   },
   "outputs": [],
   "source": [
    "from nemo.collections.tts.models import HifiGanModel\n",
    "from nemo.collections.tts.models import FastPitchModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001113fa-2365-446b-943e-fb4daf83b545",
   "metadata": {},
   "source": [
    "we will load a pretrained model to generate the voice from the spectrogram (we will later fine tune this model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28e92db0-cf97-49c1-8632-1a5fe772a3cd",
   "metadata": {
    "id": "886c91dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-07 11:31:43 cloud:56] Found existing object /home/tcapelle/.cache/torch/NeMo/NeMo_1.12.0/tts_hifigan/e6da322f0f7e7dcf3f1900a9229a7e69/tts_hifigan.nemo.\n",
      "[NeMo I 2022-12-07 11:31:43 cloud:62] Re-using file from: /home/tcapelle/.cache/torch/NeMo/NeMo_1.12.0/tts_hifigan/e6da322f0f7e7dcf3f1900a9229a7e69/tts_hifigan.nemo\n",
      "[NeMo I 2022-12-07 11:31:43 common:910] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-07 11:31:46 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.data.datalayers.MelAudioDataset\n",
      "      manifest_filepath: /home/fkreuk/data/train_finetune.txt\n",
      "      min_duration: 0.75\n",
      "      n_segments: 8192\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: true\n",
      "      batch_size: 64\n",
      "      num_workers: 4\n",
      "    \n",
      "[NeMo W 2022-12-07 11:31:46 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.data.datalayers.MelAudioDataset\n",
      "      manifest_filepath: /home/fkreuk/data/val_finetune.txt\n",
      "      min_duration: 3\n",
      "      n_segments: 66150\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 5\n",
      "      num_workers: 4\n",
      "    \n",
      "[NeMo W 2022-12-07 11:31:46 features:202] Using torch_stft is deprecated and has been removed. The values have been forcibly set to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-07 11:31:46 features:225] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-07 11:31:46 features:202] Using torch_stft is deprecated and has been removed. The values have been forcibly set to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-07 11:31:46 features:225] PADDING: 0\n",
      "[NeMo I 2022-12-07 11:31:47 save_restore_connector:243] Model HifiGanModel was successfully restored from /home/tcapelle/.cache/torch/NeMo/NeMo_1.12.0/tts_hifigan/e6da322f0f7e7dcf3f1900a9229a7e69/tts_hifigan.nemo.\n"
     ]
    }
   ],
   "source": [
    "vocoder = HifiGanModel.from_pretrained(\"tts_hifigan\")\n",
    "vocoder = vocoder.eval().cuda();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60440ec1-26d6-49ff-991b-c1b7809b6213",
   "metadata": {},
   "source": [
    "We can grab the fine tuned models from the `wandb` artifact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aede82a5-5be1-4a34-abb9-209c911c4def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which split we are using\n",
    "validation_split_artifact = f'{WANDB_ENTITY}/{WANDB_PROJECT}/9017_5_split:v0'\n",
    "\n",
    "# which model\n",
    "model_artifact = f'{WANDB_ENTITY}/{WANDB_PROJECT}/model-2022-12-06_16-43-23:v0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec083108-7bc4-48c2-8896-7ad58be68926",
   "metadata": {},
   "source": [
    "Let's log the model predictions to `W&B`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5531df3a-f71e-478a-8f9f-5933589b0913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcapecape\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tcapelle/wandb/nvidia-workshop/wandb/run-20221207_113149-3q21wru3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/capecape/tts-workshop/runs/3q21wru3\" target=\"_blank\">pious-water-10</a></strong> to <a href=\"https://wandb.ai/capecape/tts-workshop\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n"
     ]
    },
    {
     "ename": "CommError",
     "evalue": "Project capecape/tts-workshop does not contain artifact: \"model-2022-12-06_16-43-23:v0\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/nemo/lib/python3.9/site-packages/wandb/apis/normalize.py:26\u001b[0m, in \u001b[0;36mnormalize_exceptions.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/mambaforge/envs/nemo/lib/python3.9/site-packages/wandb/apis/public.py:937\u001b[0m, in \u001b[0;36mApi.artifact\u001b[0;34m(self, name, type)\u001b[0m\n\u001b[1;32m    936\u001b[0m entity, project, artifact_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_artifact_path(name)\n\u001b[0;32m--> 937\u001b[0m artifact \u001b[38;5;241m=\u001b[39m \u001b[43mArtifact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m artifact\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mtype\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/envs/nemo/lib/python3.9/site-packages/wandb/apis/public.py:4180\u001b[0m, in \u001b[0;36mArtifact.__init__\u001b[0;34m(self, client, entity, project, name, attrs)\u001b[0m\n\u001b[1;32m   4179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4180\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/nemo/lib/python3.9/site-packages/wandb/apis/public.py:4764\u001b[0m, in \u001b[0;36mArtifact._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4760\u001b[0m     response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4761\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4762\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martifact\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4763\u001b[0m ):\n\u001b[0;32m-> 4764\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4765\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProject \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not contain artifact: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   4766\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentity, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_artifact_name)\n\u001b[1;32m   4767\u001b[0m     )\n\u001b[1;32m   4768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martifact\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Project capecape/tts-workshop does not contain artifact: \"model-2022-12-06_16-43-23:v0\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m split_artifact \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39muse_artifact(validation_split_artifact)\n\u001b[1;32m      4\u001b[0m split_artifact_dir \u001b[38;5;241m=\u001b[39m split_artifact\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[0;32m----> 6\u001b[0m model_artifact \u001b[38;5;241m=\u001b[39m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_artifact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m model_artifact_dir \u001b[38;5;241m=\u001b[39m model_artifact\u001b[38;5;241m.\u001b[39mdownload()\n",
      "File \u001b[0;32m~/mambaforge/envs/nemo/lib/python3.9/site-packages/wandb/sdk/wandb_run.py:255\u001b[0m, in \u001b[0;36m_run_decorator._attach.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_is_attaching \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/nemo/lib/python3.9/site-packages/wandb/sdk/wandb_run.py:2575\u001b[0m, in \u001b[0;36mRun.use_artifact\u001b[0;34m(self, artifact_or_name, type, aliases, use_as)\u001b[0m\n\u001b[1;32m   2573\u001b[0m     name \u001b[38;5;241m=\u001b[39m artifact_or_name\n\u001b[1;32m   2574\u001b[0m public_api \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_public_api()\n\u001b[0;32m-> 2575\u001b[0m artifact \u001b[38;5;241m=\u001b[39m \u001b[43mpublic_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43martifact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m!=\u001b[39m artifact\u001b[38;5;241m.\u001b[39mtype:\n\u001b[1;32m   2577\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2578\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupplied type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m does not match type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m of artifact \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2579\u001b[0m             \u001b[38;5;28mtype\u001b[39m, artifact\u001b[38;5;241m.\u001b[39mtype, artifact\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m   2580\u001b[0m         )\n\u001b[1;32m   2581\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/nemo/lib/python3.9/site-packages/wandb/apis/normalize.py:62\u001b[0m, in \u001b[0;36mnormalize_exceptions.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CommError(message, err)\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/mambaforge/envs/nemo/lib/python3.9/site-packages/wandb/apis/normalize.py:26\u001b[0m, in \u001b[0;36mnormalize_exceptions.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhoa, you found a bug.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CommError(err\u001b[38;5;241m.\u001b[39mresponse, err)\n",
      "File \u001b[0;32m~/mambaforge/envs/nemo/lib/python3.9/site-packages/wandb/apis/public.py:937\u001b[0m, in \u001b[0;36mApi.artifact\u001b[0;34m(self, name, type)\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must specify name= to fetch an artifact.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    936\u001b[0m entity, project, artifact_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_artifact_path(name)\n\u001b[0;32m--> 937\u001b[0m artifact \u001b[38;5;241m=\u001b[39m \u001b[43mArtifact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m artifact\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mtype\u001b[39m:\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m specified but this artifact is of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    941\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/nemo/lib/python3.9/site-packages/wandb/apis/public.py:4180\u001b[0m, in \u001b[0;36mArtifact.__init__\u001b[0;34m(self, client, entity, project, name, attrs)\u001b[0m\n\u001b[1;32m   4178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs \u001b[38;5;241m=\u001b[39m attrs\n\u001b[1;32m   4179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4180\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_description \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/mambaforge/envs/nemo/lib/python3.9/site-packages/wandb/apis/public.py:4764\u001b[0m, in \u001b[0;36mArtifact._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4756\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4757\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempted to fetch artifact without alias (e.g. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<artifact_name>:v3\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<artifact_name>:latest\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   4758\u001b[0m         )\n\u001b[1;32m   4759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4760\u001b[0m     response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4761\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4762\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martifact\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4763\u001b[0m ):\n\u001b[0;32m-> 4764\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4765\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProject \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not contain artifact: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   4766\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentity, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_artifact_name)\n\u001b[1;32m   4767\u001b[0m     )\n\u001b[1;32m   4768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martifact\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs\n",
      "\u001b[0;31mCommError\u001b[0m: Project capecape/tts-workshop does not contain artifact: \"model-2022-12-06_16-43-23:v0\""
     ]
    }
   ],
   "source": [
    "wandb.init(entity=WANDB_ENTITY, project=WANDB_PROJECT, job_type=\"fastptich_validation\")\n",
    "\n",
    "split_artifact = wandb.use_artifact(validation_split_artifact)\n",
    "split_artifact_dir = split_artifact.download()\n",
    "\n",
    "model_artifact = wandb.use_artifact(model_artifact, type='model')\n",
    "model_artifact_dir = model_artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bb5a72-b5ac-49fb-a384-520705786999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls(path): return list(Path(path).iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df519bc1-3b42-4ef6-aef7-378c8b767000",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls(split_artifact_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d421e5-9ecb-4dce-a53a-97270785c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls(model_artifact_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b3158e-2897-4f11-a7b1-765e4e88b04d",
   "metadata": {
    "id": "0a4c986f"
   },
   "outputs": [],
   "source": [
    "def infer(spec_gen_model, vocoder_model, str_input, speaker=None):\n",
    "    \"\"\"\n",
    "    Synthesizes spectrogram and audio from a text string given a spectrogram synthesis and vocoder model.\n",
    "    \n",
    "    Args:\n",
    "        spec_gen_model: Spectrogram generator model (FastPitch in our case)\n",
    "        vocoder_model: Vocoder model (HiFiGAN in our case)\n",
    "        str_input: Text input for the synthesis\n",
    "        speaker: Speaker ID\n",
    "    \n",
    "    Returns:\n",
    "        spectrogram and waveform of the synthesized audio.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        parsed = spec_gen_model.parse(str_input)\n",
    "        if speaker is not None:\n",
    "            speaker = torch.tensor([speaker]).long().to(device=spec_gen_model.device)\n",
    "        spectrogram = spec_gen_model.generate_spectrogram(tokens=parsed, speaker=speaker)\n",
    "        audio = vocoder_model.convert_spectrogram_to_audio(spec=spectrogram)\n",
    "        \n",
    "    if spectrogram is not None:\n",
    "        if isinstance(spectrogram, torch.Tensor):\n",
    "            spectrogram = spectrogram.to('cpu').numpy()\n",
    "        if len(spectrogram.shape) == 3:\n",
    "            spectrogram = spectrogram[0]\n",
    "    if isinstance(audio, torch.Tensor):\n",
    "        audio = audio.to('cpu').numpy()\n",
    "    return spectrogram, audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e2c2d-d164-4725-b159-2bbf268182fb",
   "metadata": {
    "id": "8901f88b"
   },
   "outputs": [],
   "source": [
    "last_ckpt = str(ls(artifact_dir)[0])\n",
    "print(last_ckpt)\n",
    "\n",
    "spec_model = FastPitchModel.load_from_checkpoint(last_ckpt)\n",
    "spec_model.eval().cuda();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec1b18-11e1-419e-8e35-da71de9ff752",
   "metadata": {},
   "source": [
    "### View results in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be1a2ba-ddad-4df0-a510-76fa6b23d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_json(Path(split_artifact_dir)/f\"{SPEAKER_ID}_manifest_valid_local.json\", lines=True)\n",
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3851c08c-e72d-49af-b51e-56902165a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio(text, speaker_id):\n",
    "    \"Generate MEL and Synth Audio\"\n",
    "    spec, audio = infer(spec_model, vocoder, text, speaker=speaker_id)\n",
    "    return spec, audio.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6810c3-2d73-485e-9730-52ee64867bdb",
   "metadata": {
    "id": "8901f88b"
   },
   "outputs": [],
   "source": [
    "new_speaker_id = SPEAKER_ID\n",
    "duration_mins = 5\n",
    "mixing = False\n",
    "original_speaker_id = \"ljspeech\"\n",
    "\n",
    "for _, val_record in valid_df.iterrows():\n",
    "    print(\"Real validation audio\")\n",
    "    ipd.display(ipd.Audio(val_record['audio_filepath'], rate=22050))\n",
    "    print(f\"SYNTHESIZED FOR -- Speaker: {new_speaker_id} | Dataset size: {duration_mins} mins | Mixing:{mixing} | Text: {val_record['text']}\")\n",
    "    spec, audio = generate_audio(val_record[\"text\"], new_speaker_id)\n",
    "    ipd.display(ipd.Audio(audio, rate=22050))\n",
    "    %matplotlib inline\n",
    "    imshow(spec, origin=\"lower\", aspect=\"auto\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3753d143-b2c8-420c-9d8f-31cb59c03546",
   "metadata": {},
   "source": [
    "### The same on a wandb.Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4306977-f04d-46da-92ea-a7201eb4d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = wandb.Table(columns=['Text', 'Real validation audio', f'Audio Speaker {new_speaker_id}', 'Spec'])\n",
    "\n",
    "sample_rate=22050\n",
    "\n",
    "for _, val_record in valid_df.iterrows():\n",
    "    speaker_spec, speaker_audio = generate_audio(val_record['text'], speaker_id=new_speaker_id)\n",
    "    row = [val_record[\"text_no_preprocessing\"],\n",
    "           wandb.Audio(val_record['audio_filepath'], sample_rate=sample_rate), \n",
    "           wandb.Audio(speaker_audio.flatten(), sample_rate=sample_rate),\n",
    "           wandb.Image(speaker_spec)]\n",
    "    table.add_data(*row)\n",
    "\n",
    "wandb.log({\"table\": table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2bdd02-66e8-43c7-9343-012f7e157d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
